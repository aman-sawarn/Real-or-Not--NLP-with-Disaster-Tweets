{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble Embeddings with attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6ca30b5153ba445aba1f6c8e02572907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33824e61536b4d66afca544b57522507",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eee3b631420e4bb78bd2c20c488679b5",
              "IPY_MODEL_ba16d539843b40728deaa5961a3dba6b"
            ]
          }
        },
        "33824e61536b4d66afca544b57522507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eee3b631420e4bb78bd2c20c488679b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ea1ed6957d2c4c9fba0a9921f88217a7",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 6090,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6090,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be9259930e6a490996d4a2f29632e42d"
          }
        },
        "ba16d539843b40728deaa5961a3dba6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b5cf333e656c413bb594e2015e46ad3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 6090/6090 [00:04&lt;00:00, 1327.83it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_201df7b729624a1886b1df9656a14973"
          }
        },
        "ea1ed6957d2c4c9fba0a9921f88217a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be9259930e6a490996d4a2f29632e42d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5cf333e656c413bb594e2015e46ad3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "201df7b729624a1886b1df9656a14973": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6fa56ca7c5d4fa79822668edd122b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4601229ff2344f35a708a326331792ad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27a323119c7b48508828bc819fc97bdd",
              "IPY_MODEL_8a95c10493dc45f38caca4f3a05458dd"
            ]
          }
        },
        "4601229ff2344f35a708a326331792ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27a323119c7b48508828bc819fc97bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d92d006ea96b4b48adbecddd7a8822ae",
            "_dom_classes": [],
            "description": "Converting examples to features",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1523,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1523,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f059268509c426c834e150779f2b892"
          }
        },
        "8a95c10493dc45f38caca4f3a05458dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25d5032a7ee34602bcac18df2f2bff7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 1523/1523 [00:01&lt;00:00, 1294.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_768ad106f30745c4bf64b08fd6cd1f67"
          }
        },
        "d92d006ea96b4b48adbecddd7a8822ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f059268509c426c834e150779f2b892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25d5032a7ee34602bcac18df2f2bff7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "768ad106f30745c4bf64b08fd6cd1f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2GTcNso0nq4",
        "colab_type": "text"
      },
      "source": [
        "https://mlwhiz.com/blog/2019/02/19/siver_medal_kaggle_learnings/\n",
        "\n",
        "https://towardsdatascience.com/https-medium-com-tanaygahlot-moving-beyond-the-distributional-model-for-word-representation-b0823f1769f8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQDLFg4Kf1w0",
        "colab_type": "code",
        "outputId": "096dac15-14ca-4efb-e5b7-b9fe74624978",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from __future__ import absolute_import, division\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gensim\n",
        "from tqdm import tqdm\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "lc = LancasterStemmer()\n",
        "from nltk.stem import SnowballStemmer\n",
        "sb = SnowballStemmer(\"english\")\n",
        "import gc\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate, LSTM, GRU\n",
        "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "import sys\n",
        "from os.path import dirname\n",
        "#sys.path.append(dirname(dirname(__file__)))\n",
        "from keras import initializers\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras import backend as K\n",
        "\n",
        "import spacy\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taynK1yPntgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/bfelbo/DeepMoji/blob/master/deepmoji/attlayer.py\n",
        "class AttentionWeightedAverage(Layer):\n",
        "    \"\"\"\n",
        "    Computes a weighted average of the different channels across timesteps.\n",
        "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, return_attention=False, **kwargs):\n",
        "        self.init = initializers.get('uniform')\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        super(AttentionWeightedAverage, self).__init__(** kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 initializer=self.init)\n",
        "        self.trainable_weights = [self.W]\n",
        "        super(AttentionWeightedAverage, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        # computes a probability distribution over the timesteps\n",
        "        # uses 'max trick' for numerical stability\n",
        "        # reshape is done to avoid issue with Tensorflow\n",
        "        # and 1-dimensional weights\n",
        "        logits = K.dot(x, self.W)\n",
        "        x_shape = K.shape(x)\n",
        "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
        "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
        "\n",
        "        # masked timesteps have zero weight\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, K.floatx())\n",
        "            ai = ai * mask\n",
        "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
        "        weighted_input = x * K.expand_dims(att_weights)\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "        if self.return_attention:\n",
        "            return [result, att_weights]\n",
        "        return result\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        return self.compute_output_shape(input_shape)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        output_len = input_shape[2]\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
        "        return (input_shape[0], output_len)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        if isinstance(input_mask, list):\n",
        "            return [None] * len(input_mask)\n",
        "        else:\n",
        "            return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlcGxRKWn02W",
        "colab_type": "code",
        "outputId": "d417d2fc-4489-4e66-926f-e263864f5b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# https://www.kaggle.com/cpmpml/spell-checker-using-word2vec\n",
        "spell_model = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/My Drive/Colab Notebooks/wiki-news-300d-1M.vec')\n",
        "words = spell_model.index2word\n",
        "w_rank = {}\n",
        "for i,word in enumerate(words):\n",
        "    w_rank[word] = i\n",
        "WORDS = w_rank"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwtCcEs4n05A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words(text):\n",
        "   return re.findall(r'\\w+', text.lower())\n",
        "def P(word): \n",
        "    \"Probability of `word`.\"\n",
        "    # use inverse of rank as proxy\n",
        "    # returns 0 if the word isn't in the dictionary\n",
        "    return - WORDS.get(word, 0)\n",
        "def correction(word): \n",
        "    \"Most probable spelling correction for word.\"\n",
        "    return max(candidates(word), key=P)\n",
        "def candidates(word): \n",
        "    \"Generate possible spelling corrections for word.\"\n",
        "    return (known([word]) or known(edits1(word)) or [word])\n",
        "def known(words): \n",
        "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "    return set(w for w in words if w in WORDS)\n",
        "def edits1(word):\n",
        "    \"All edits that are one edit away from `word`.\"\n",
        "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "    return set(deletes + transposes + replaces + inserts)\n",
        "def edits2(word): \n",
        "    \"All edits that are two edits away from `word`.\"\n",
        "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
        "def singlify(word):\n",
        "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ANSM-f8oNQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# modified version of \n",
        "# https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings\n",
        "# https://www.kaggle.com/danofer/different-embeddings-with-attention-fork\n",
        "# https://www.kaggle.com/shujian/different-embeddings-with-attention-fork-fork\n",
        "def load_glove(word_dict, lemma_dict):\n",
        "    EMBEDDING_FILE = '/content/drive/My Drive/Colab Notebooks/glove.840B.300d.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
        "    embed_size = 300\n",
        "    nb_words = len(word_dict)+1\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
        "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
        "    print(unknown_vector[:5])\n",
        "    for key in tqdm(word_dict):\n",
        "        word = key\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.lower()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.upper()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.capitalize()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = ps.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lc.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = sb.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lemma_dict[key]\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        if len(key) > 1:\n",
        "            word = correction(key)\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[word_dict[key]] = embedding_vector\n",
        "                continue\n",
        "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
        "    return embedding_matrix, nb_words \n",
        "\n",
        "\n",
        "def load_fasttext(word_dict, lemma_dict):\n",
        "    EMBEDDING_FILE = '/content/drive/My Drive/Colab Notebooks/paragram_300_sl999.txt'\n",
        "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
        "    embed_size = 300\n",
        "    nb_words = len(word_dict)+1\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
        "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
        "    print(unknown_vector[:5])\n",
        "    for key in tqdm(word_dict):\n",
        "        word = key\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.lower()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.upper()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.capitalize()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = ps.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lc.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = sb.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lemma_dict[key]\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        if len(key) > 1:\n",
        "            word = correction(key)\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[word_dict[key]] = embedding_vector\n",
        "                continue\n",
        "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
        "    return embedding_matrix, nb_words \n",
        "\n",
        "\n",
        "def load_para(word_dict, lemma_dict):\n",
        "    EMBEDDING_FILE = '/content/drive/My Drive/Colab Notebooks/paragram_300_sl999.txt'\n",
        "    def get_coefs(word,*arr): \n",
        "      return word, np.asarray(arr, dtype='float32')\n",
        "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\", errors='ignore') if len(o)>100)\n",
        "    embed_size = 300\n",
        "    nb_words = len(word_dict)+1\n",
        "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
        "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
        "    print(unknown_vector[:5])\n",
        "    for key in tqdm(word_dict):\n",
        "        word = key\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.lower()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.upper()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = key.capitalize()\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = ps.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lc.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = sb.stem(key)\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        word = lemma_dict[key]\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[word_dict[key]] = embedding_vector\n",
        "            continue\n",
        "        if len(key) > 1:\n",
        "            word = correction(key)\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[word_dict[key]] = embedding_vector\n",
        "                continue\n",
        "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
        "    return embedding_matrix, nb_words \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsmjUtqJxlsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "    \n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-MbQyz2o2sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = SpatialDropout1D(0.3)(x)\n",
        "    x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True))(x)\n",
        "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True))(x1)\n",
        "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
        "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
        "    conc = Concatenate()([max_pool1, max_pool2])\n",
        "    predictions = Dense(1, activation='sigmoid')(conc)\n",
        "    model = Model(inputs=inp, outputs=predictions)\n",
        "    adam = optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4WK7diFxilF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwTCmKXKo9av",
        "colab_type": "code",
        "outputId": "5cf6880c-bb8f-483e-8906-4b8ad09cbf60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "start_time = time.time()\n",
        "print(\"Loading data ...\")\n",
        "train = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv').fillna(' ')\n",
        "test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/test.csv').fillna(' ')\n",
        "train_text = train['text']\n",
        "test_text = test['text']\n",
        "text_list = pd.concat([train_text, test_text])\n",
        "y = train['target'].values\n",
        "num_train_data = y.shape[0]\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data ...\n",
            "--- 2.704399347305298 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph1QQLNARWU2",
        "colab_type": "code",
        "outputId": "934fbfdd-8f69-45a8-c741-7fb429b3ac1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "ids_with_target_error = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
        "train[train['id'].isin(ids_with_target_error)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>328</td>\n",
              "      <td>annihilated</td>\n",
              "      <td></td>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>443</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td></td>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>513</td>\n",
              "      <td>army</td>\n",
              "      <td>Studio</td>\n",
              "      <td>But if you build an army of 100 dogs and their...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>2619</td>\n",
              "      <td>crashed</td>\n",
              "      <td></td>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVH...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>3640</td>\n",
              "      <td>desolation</td>\n",
              "      <td>Quilmes , Arg</td>\n",
              "      <td>This desperation dislocation\\nSeparation conde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>3900</td>\n",
              "      <td>devastated</td>\n",
              "      <td>PG Chillin!</td>\n",
              "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>4342</td>\n",
              "      <td>dust%20storm</td>\n",
              "      <td>chicago</td>\n",
              "      <td>Going to a fest? Bring swimming goggles for th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>5781</td>\n",
              "      <td>forest%20fires</td>\n",
              "      <td></td>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nP...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>6552</td>\n",
              "      <td>injury</td>\n",
              "      <td>Saint Paul</td>\n",
              "      <td>My prediction for the Vikings game this Sunday...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>6554</td>\n",
              "      <td>injury</td>\n",
              "      <td></td>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>6570</td>\n",
              "      <td>injury</td>\n",
              "      <td></td>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>6701</td>\n",
              "      <td>lava</td>\n",
              "      <td>Nashville, TN</td>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>6702</td>\n",
              "      <td>lava</td>\n",
              "      <td>probably watching survivor</td>\n",
              "      <td>The sunset looked like an erupting volcano ......</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>6729</td>\n",
              "      <td>lava</td>\n",
              "      <td>Clayton, NC</td>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/T...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>6861</td>\n",
              "      <td>mass%20murder</td>\n",
              "      <td>i'm a Citizen of the World</td>\n",
              "      <td>If abortion is murder then blowjobs are cannib...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>7226</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>on to the next adventure</td>\n",
              "      <td>Of course the one day I have to dress professi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "229    328  ...      1\n",
              "301    443  ...      1\n",
              "356    513  ...      1\n",
              "1822  2619  ...      1\n",
              "2536  3640  ...      1\n",
              "2715  3900  ...      1\n",
              "3024  4342  ...      1\n",
              "4068  5781  ...      1\n",
              "4609  6552  ...      1\n",
              "4611  6554  ...      1\n",
              "4622  6570  ...      1\n",
              "4713  6701  ...      1\n",
              "4714  6702  ...      1\n",
              "4732  6729  ...      1\n",
              "4820  6861  ...      1\n",
              "5068  7226  ...      1\n",
              "\n",
              "[16 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abI5CFt-RWSa",
        "colab_type": "code",
        "outputId": "267b0f12-6b75-4324-a882-b03618671415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "train.at[train['id'].isin(ids_with_target_error),'target'] = 0\n",
        "train[train['id'].isin(ids_with_target_error)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>328</td>\n",
              "      <td>annihilated</td>\n",
              "      <td></td>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>443</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td></td>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>513</td>\n",
              "      <td>army</td>\n",
              "      <td>Studio</td>\n",
              "      <td>But if you build an army of 100 dogs and their...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>2619</td>\n",
              "      <td>crashed</td>\n",
              "      <td></td>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVH...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>3640</td>\n",
              "      <td>desolation</td>\n",
              "      <td>Quilmes , Arg</td>\n",
              "      <td>This desperation dislocation\\nSeparation conde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>3900</td>\n",
              "      <td>devastated</td>\n",
              "      <td>PG Chillin!</td>\n",
              "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>4342</td>\n",
              "      <td>dust%20storm</td>\n",
              "      <td>chicago</td>\n",
              "      <td>Going to a fest? Bring swimming goggles for th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>5781</td>\n",
              "      <td>forest%20fires</td>\n",
              "      <td></td>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nP...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>6552</td>\n",
              "      <td>injury</td>\n",
              "      <td>Saint Paul</td>\n",
              "      <td>My prediction for the Vikings game this Sunday...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>6554</td>\n",
              "      <td>injury</td>\n",
              "      <td></td>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hop...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>6570</td>\n",
              "      <td>injury</td>\n",
              "      <td></td>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>6701</td>\n",
              "      <td>lava</td>\n",
              "      <td>Nashville, TN</td>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>6702</td>\n",
              "      <td>lava</td>\n",
              "      <td>probably watching survivor</td>\n",
              "      <td>The sunset looked like an erupting volcano ......</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>6729</td>\n",
              "      <td>lava</td>\n",
              "      <td>Clayton, NC</td>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/T...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>6861</td>\n",
              "      <td>mass%20murder</td>\n",
              "      <td>i'm a Citizen of the World</td>\n",
              "      <td>If abortion is murder then blowjobs are cannib...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>7226</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>on to the next adventure</td>\n",
              "      <td>Of course the one day I have to dress professi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "229    328  ...      0\n",
              "301    443  ...      0\n",
              "356    513  ...      0\n",
              "1822  2619  ...      0\n",
              "2536  3640  ...      0\n",
              "2715  3900  ...      0\n",
              "3024  4342  ...      0\n",
              "4068  5781  ...      0\n",
              "4609  6552  ...      0\n",
              "4611  6554  ...      0\n",
              "4622  6570  ...      0\n",
              "4713  6701  ...      0\n",
              "4714  6702  ...      0\n",
              "4732  6729  ...      0\n",
              "4820  6861  ...      0\n",
              "5068  7226  ...      0\n",
              "\n",
              "[16 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O52mMN_u2eE_",
        "colab_type": "code",
        "outputId": "54fdb328-8af0-42c8-d789-023307636046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "train['word_len']=train['text'].apply(lambda x:len(x))\n",
        "test['word_len']=test['text'].apply(lambda x:len(x))\n",
        "print(\"mean : \",train['word_len'].mean())\n",
        "print(\"median : \",train['word_len'].median())\n",
        "print(\"mean : \",test['word_len'].mean())\n",
        "print(\"median : \",test['word_len'].median())\n",
        "train['word_len']=train['text'].apply(lambda x:len(x))\n",
        "# print(train['word_len'].quantile(0.10))\n",
        "# print(train['word_len'].quantile(0.20))\n",
        "# print(train['word_len'].quantile(0.30))\n",
        "# print(train['word_len'].quantile(0.40))\n",
        "# print(train['word_len'].quantile(0.50))\n",
        "# print(train['word_len'].quantile(0.60))\n",
        "# print(train['word_len'].quantile(0.70))\n",
        "# print(train['word_len'].quantile(0.80))\n",
        "# print(train['word_len'].quantile(0.90))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean :  101.03743596479706\n",
            "median :  107.0\n",
            "mean :  102.10818265399939\n",
            "median :  109.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_tH1Ongphrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_821VkOo9dj",
        "colab_type": "code",
        "outputId": "e904a47f-198d-476d-b0c3-cc7200ea790e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "start_time = time.time()\n",
        "print(\"Spacy NLP ...\")\n",
        "nlp = spacy.load('/content/drive/My Drive/Colab Notebooks/en_core_web_lg-2.1.0/en_core_web_lg/en_core_web_lg-2.1.0', disable=['parser','ner','tagger'])\n",
        "nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n",
        "word_dict = {}\n",
        "word_index = 1\n",
        "lemma_dict = {}\n",
        "docs = nlp.pipe(text_list, n_threads = 2)\n",
        "word_sequences = []\n",
        "for doc in tqdm(docs):\n",
        "    word_seq = []\n",
        "    for token in doc:\n",
        "        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n",
        "            word_dict[token.text] = word_index\n",
        "            word_index += 1\n",
        "            lemma_dict[token.text] = token.lemma_\n",
        "        if token.pos_ is not \"PUNCT\":\n",
        "            word_seq.append(word_dict[token.text])\n",
        "    word_sequences.append(word_seq)\n",
        "del docs\n",
        "gc.collect()\n",
        "train_word_sequences = word_sequences[:num_train_data]\n",
        "test_word_sequences = word_sequences[num_train_data:]\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spacy NLP ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "10876it [00:04, 2313.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 39.17442083358765 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hT5Cjnjo9ga",
        "colab_type": "code",
        "outputId": "80470f82-04d3-4cd2-80db-f49469fda87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# hyperparameters\n",
        "max_length = 140\n",
        "embedding_size = 600\n",
        "learning_rate = 0.001\n",
        "batch_size = 512\n",
        "num_epoch = 4\n",
        "\n",
        "train_word_sequences = pad_sequences(train_word_sequences, maxlen=max_length, padding='post')\n",
        "test_word_sequences = pad_sequences(test_word_sequences, maxlen=max_length, padding='post')\n",
        "print(train_word_sequences[:10])\n",
        "print(test_word_sequences[:10])\n",
        "pred_prob = np.zeros((len(test_word_sequences),), dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1   2   3 ...   0   0   0]\n",
            " [ 15  16  17 ...   0   0   0]\n",
            " [ 23  24  25 ...   0   0   0]\n",
            " ...\n",
            " [ 86  87  88 ...   0   0   0]\n",
            " [ 96  97  98 ...   0   0   0]\n",
            " [ 86  87 105 ...   0   0   0]]\n",
            "[[  46  762   57 ...    0    0    0]\n",
            " [8964  461    8 ...    0    0    0]\n",
            " [ 630  108   57 ...    0    0    0]\n",
            " ...\n",
            " [1698  168  323 ...    0    0    0]\n",
            " [ 157   57 2501 ...    0    0    0]\n",
            " [7829  972  168 ...    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iqEvXT1o9jD",
        "colab_type": "code",
        "outputId": "8f444c9c-5a1c-44b2-8694-1b039b2b7131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start_time = time.time()\n",
        "print(\"Loading embedding matrix ...\")\n",
        "embedding_matrix_glove, nb_words = load_glove(word_dict, lemma_dict)\n",
        "embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_fasttext), axis=1)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading embedding matrix ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 886/34503 [00:00<00:03, 8840.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34503/34503 [00:06<00:00, 4960.29it/s]\n",
            "  3%|▎         | 1175/34503 [00:00<00:02, 11719.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34503/34503 [00:07<00:00, 4737.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 244.89796924591064 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gLsED2lpx9q",
        "colab_type": "code",
        "outputId": "f1acdc14-2178-45d6-9b51-f5813dc273cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "start_time = time.time()\n",
        "print(\"Start training ...\")\n",
        "model = model_lstm_atten(embedding_matrix, nb_words, embedding_size)\n",
        "model.fit(train_word_sequences, y, batch_size=batch_size, epochs=num_epoch-1, verbose=2)\n",
        "pred_prob += 0.15*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
        "model.fit(train_word_sequences, y, batch_size=batch_size, epochs=1, verbose=2)\n",
        "pred_prob += 0.35*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
        "del model, embedding_matrix_fasttext, embedding_matrix\n",
        "gc.collect()\n",
        "K.clear_session()\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training ...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/3\n",
            " - 10s - loss: 0.6110 - acc: 0.6585\n",
            "Epoch 2/3\n",
            " - 3s - loss: 0.4416 - acc: 0.8034\n",
            "Epoch 3/3\n",
            " - 3s - loss: 0.3975 - acc: 0.8265\n",
            "Epoch 1/1\n",
            " - 3s - loss: 0.3635 - acc: 0.8467\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "--- 28.27223563194275 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9KIaKj-pyBs",
        "colab_type": "code",
        "outputId": "0045af10-3004-4ab3-abc5-4969f9c222e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "start_time = time.time()\n",
        "print(\"Loading embedding matrix ...\")\n",
        "embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "embedding_matrix_para, nb_words = load_para(word_dict, lemma_dict)\n",
        "# embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_para), axis=1)\n",
        "embedding_matrix = np.concatenate((0.60*embedding_matrix_glove, 0.40*embedding_matrix_fasttext), axis=1)\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading embedding matrix ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1087/34503 [00:00<00:03, 10853.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34503/34503 [00:07<00:00, 4765.53it/s]\n",
            "  3%|▎         | 1198/34503 [00:00<00:02, 11972.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34503/34503 [00:07<00:00, 4685.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- 26.496766328811646 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKhKhGNWH7BR",
        "colab_type": "code",
        "outputId": "08e12a13-4796-48d1-d85c-55bc4e5daa88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_fasttext.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34504, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMmkyIUZp4N9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start_time = time.time()\n",
        "# print(\"Start training ...\")\n",
        "model = model_lstm_atten(embedding_matrix, nb_words, embedding_size)\n",
        "# model.fit(train_word_sequences, y, batch_size=batch_size, epochs=num_epoch-1, verbose=2)\n",
        "# pred_prob += 0.15*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
        "# model.fit(train_word_sequences, y, batch_size=batch_size, epochs=1, verbose=2)\n",
        "# pred_prob += 0.35*np.squeeze(model.predict(test_word_sequences, batch_size=batch_size, verbose=2))\n",
        "# print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB6MauM242bx",
        "colab_type": "code",
        "outputId": "cbe45c4b-f0d4-46a0-d680-b19240f7a5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "# from sklearn import model_selection   \n",
        "# kfold=model_selection.KFold\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix_fasttext, nb_words, embedding_size=300)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 10s - loss: 0.6354 - acc: 0.6173 - val_loss: 0.5404 - val_acc: 0.7574\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4991 - acc: 0.7709 - val_loss: 0.4778 - val_acc: 0.7925\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4278 - acc: 0.8135 - val_loss: 0.5211 - val_acc: 0.7784\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.4119 - acc: 0.8203 - val_loss: 0.4732 - val_acc: 0.7889\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3765 - acc: 0.8417 - val_loss: 0.4707 - val_acc: 0.7994\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3608 - acc: 0.8497 - val_loss: 0.5251 - val_acc: 0.7700\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3455 - acc: 0.8537 - val_loss: 0.4933 - val_acc: 0.7878\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3188 - acc: 0.8707 - val_loss: 0.5292 - val_acc: 0.7826\n",
            "Epoch 9/15\n",
            " - 4s - loss: 0.3080 - acc: 0.8749 - val_loss: 0.5032 - val_acc: 0.7857\n",
            "Epoch 10/15\n",
            " - 4s - loss: 0.2810 - acc: 0.8879 - val_loss: 0.5512 - val_acc: 0.7763\n",
            "Epoch 11/15\n",
            " - 4s - loss: 0.2552 - acc: 0.8989 - val_loss: 0.6008 - val_acc: 0.7500\n",
            "Epoch 12/15\n",
            " - 4s - loss: 0.2405 - acc: 0.9068 - val_loss: 0.6074 - val_acc: 0.7710\n",
            "Epoch 13/15\n",
            " - 4s - loss: 0.2032 - acc: 0.9242 - val_loss: 0.6672 - val_acc: 0.7705\n",
            "Epoch 14/15\n",
            " - 4s - loss: 0.1998 - acc: 0.9226 - val_loss: 0.7414 - val_acc: 0.7694\n",
            "Epoch 15/15\n",
            " - 4s - loss: 0.1953 - acc: 0.9221 - val_loss: 0.6648 - val_acc: 0.7810\n",
            "<keras.callbacks.History object at 0x7fc79b00b908>\n",
            "1 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6209 - acc: 0.6525 - val_loss: 0.5575 - val_acc: 0.7425\n",
            "Epoch 2/15\n",
            " - 4s - loss: 0.4740 - acc: 0.7876 - val_loss: 0.5388 - val_acc: 0.7483\n",
            "Epoch 3/15\n",
            " - 4s - loss: 0.4340 - acc: 0.8049 - val_loss: 0.4808 - val_acc: 0.7824\n",
            "Epoch 4/15\n",
            " - 4s - loss: 0.4035 - acc: 0.8240 - val_loss: 0.4780 - val_acc: 0.7840\n",
            "Epoch 5/15\n",
            " - 4s - loss: 0.3741 - acc: 0.8406 - val_loss: 0.5043 - val_acc: 0.7746\n",
            "Epoch 6/15\n",
            " - 4s - loss: 0.3597 - acc: 0.8501 - val_loss: 0.4990 - val_acc: 0.7856\n",
            "Epoch 7/15\n",
            " - 4s - loss: 0.3390 - acc: 0.8557 - val_loss: 0.5136 - val_acc: 0.7761\n",
            "Epoch 8/15\n",
            " - 4s - loss: 0.3218 - acc: 0.8657 - val_loss: 0.5616 - val_acc: 0.7646\n",
            "Epoch 9/15\n",
            " - 4s - loss: 0.3117 - acc: 0.8713 - val_loss: 0.5284 - val_acc: 0.7714\n",
            "Epoch 10/15\n",
            " - 4s - loss: 0.2742 - acc: 0.8895 - val_loss: 0.6063 - val_acc: 0.7646\n",
            "Epoch 11/15\n",
            " - 4s - loss: 0.2545 - acc: 0.9005 - val_loss: 0.6453 - val_acc: 0.7520\n",
            "Epoch 12/15\n",
            " - 4s - loss: 0.2214 - acc: 0.9117 - val_loss: 0.6817 - val_acc: 0.7373\n",
            "Epoch 13/15\n",
            " - 4s - loss: 0.1972 - acc: 0.9217 - val_loss: 0.7742 - val_acc: 0.7278\n",
            "Epoch 14/15\n",
            " - 4s - loss: 0.1925 - acc: 0.9278 - val_loss: 0.7345 - val_acc: 0.7225\n",
            "Epoch 15/15\n",
            " - 4s - loss: 0.1690 - acc: 0.9357 - val_loss: 0.7860 - val_acc: 0.7383\n",
            "<keras.callbacks.History object at 0x7fc78ffa4d68>\n",
            "2 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6102 - acc: 0.6755 - val_loss: 0.5344 - val_acc: 0.7472\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4709 - acc: 0.7944 - val_loss: 0.4946 - val_acc: 0.7735\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4115 - acc: 0.8226 - val_loss: 0.5003 - val_acc: 0.7772\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.3882 - acc: 0.8354 - val_loss: 0.5160 - val_acc: 0.7751\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3670 - acc: 0.8450 - val_loss: 0.5664 - val_acc: 0.7509\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3492 - acc: 0.8559 - val_loss: 0.5378 - val_acc: 0.7546\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3236 - acc: 0.8665 - val_loss: 0.5679 - val_acc: 0.7467\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3022 - acc: 0.8772 - val_loss: 0.5726 - val_acc: 0.7683\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.2823 - acc: 0.8870 - val_loss: 0.6107 - val_acc: 0.7562\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.2609 - acc: 0.8972 - val_loss: 0.6179 - val_acc: 0.7556\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.2277 - acc: 0.9123 - val_loss: 0.7078 - val_acc: 0.7462\n",
            "Epoch 12/15\n",
            " - 3s - loss: 0.2075 - acc: 0.9193 - val_loss: 0.7171 - val_acc: 0.7362\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.1967 - acc: 0.9229 - val_loss: 0.7877 - val_acc: 0.7225\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.1728 - acc: 0.9370 - val_loss: 0.8524 - val_acc: 0.7299\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.1578 - acc: 0.9429 - val_loss: 0.8859 - val_acc: 0.7252\n",
            "<keras.callbacks.History object at 0x7fc78f984ef0>\n",
            "3 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6263 - acc: 0.6394 - val_loss: 0.5445 - val_acc: 0.7147\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4924 - acc: 0.7643 - val_loss: 0.4729 - val_acc: 0.7851\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4352 - acc: 0.8051 - val_loss: 0.4499 - val_acc: 0.7835\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.4240 - acc: 0.8124 - val_loss: 0.4231 - val_acc: 0.8103\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3947 - acc: 0.8324 - val_loss: 0.4337 - val_acc: 0.8119\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3745 - acc: 0.8469 - val_loss: 0.4421 - val_acc: 0.7909\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3680 - acc: 0.8485 - val_loss: 0.4463 - val_acc: 0.7993\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3332 - acc: 0.8646 - val_loss: 0.4690 - val_acc: 0.8019\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.3180 - acc: 0.8722 - val_loss: 0.4591 - val_acc: 0.7993\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.2808 - acc: 0.8932 - val_loss: 0.5034 - val_acc: 0.7966\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.2463 - acc: 0.9077 - val_loss: 0.5570 - val_acc: 0.7882\n",
            "Epoch 12/15\n",
            " - 4s - loss: 0.2162 - acc: 0.9219 - val_loss: 0.5792 - val_acc: 0.7714\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.1963 - acc: 0.9273 - val_loss: 0.6587 - val_acc: 0.7819\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.2025 - acc: 0.9236 - val_loss: 0.5920 - val_acc: 0.7824\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.1807 - acc: 0.9322 - val_loss: 0.7604 - val_acc: 0.7551\n",
            "<keras.callbacks.History object at 0x7fc78f3ea278>\n",
            "4 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "nan% (+/- nan%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nchQzO_eEXK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# original=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Original.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drMFtDWDLcW6",
        "colab_type": "code",
        "outputId": "aa8fd788-9e61-4aab-b72a-67a23786a627",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "# f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324403789611239"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqey5liEp4Q2",
        "colab_type": "code",
        "outputId": "e6c7dcee-e223-42ef-db9a-4a5b9fd74c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "submission['target'] = np.array(pred_prob.round())\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "original=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Original.csv\")\n",
        "original['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1861\n",
              "1    1402\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vJrlV_Cp4UH",
        "colab_type": "code",
        "outputId": "5d789c18-8215-46d8-9527-f69c9e8bb4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "submission['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    2056\n",
              "1.0    1207\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4pnxTtKHj2M",
        "colab_type": "code",
        "outputId": "b25956ab-520a-48c5-b7c7-6853de707908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpiC-wAGaPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_cnn(embedding_matrix):\n",
        "    filter_sizes = [1,2,3,5]\n",
        "    num_filters = 36\n",
        "    embedding_size=300\n",
        "\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, 300, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Reshape((max_length, 300, 1))(x)\n",
        "\n",
        "    maxpool_pool = []\n",
        "    for i in range(len(filter_sizes)):\n",
        "        conv = Conv2D(num_filters, kernel_size=(filter_sizes[i], embedding_size),\n",
        "                                     kernel_initializer='he_normal', activation='relu')(x)\n",
        "        maxpool_pool.append(MaxPool2D(pool_size=(max_length - filter_sizes[i] + 1, 1))(conv))\n",
        "\n",
        "    z = Concatenate(axis=1)(maxpool_pool)   \n",
        "    z = Flatten()(z)\n",
        "    z = Dropout(0.1)(z)\n",
        "\n",
        "    outp = Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WeS302hKRru",
        "colab_type": "code",
        "outputId": "f2010029-98e6-4e6a-bb63-32046cc9c3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(64, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_cnn(embedding_matrix_fasttext)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 4s - loss: 0.7283 - acc: 0.6045 - val_loss: 0.6005 - val_acc: 0.6896\n",
            "Epoch 2/15\n",
            " - 1s - loss: 0.5359 - acc: 0.7322 - val_loss: 0.5213 - val_acc: 0.7600\n",
            "Epoch 3/15\n",
            " - 1s - loss: 0.4601 - acc: 0.7807 - val_loss: 0.5089 - val_acc: 0.7652\n",
            "Epoch 4/15\n",
            " - 1s - loss: 0.4187 - acc: 0.8115 - val_loss: 0.5053 - val_acc: 0.7631\n",
            "Epoch 5/15\n",
            " - 1s - loss: 0.3851 - acc: 0.8320 - val_loss: 0.4887 - val_acc: 0.7778\n",
            "Epoch 6/15\n",
            " - 1s - loss: 0.3604 - acc: 0.8487 - val_loss: 0.4868 - val_acc: 0.7694\n",
            "Epoch 7/15\n",
            " - 1s - loss: 0.3405 - acc: 0.8592 - val_loss: 0.4869 - val_acc: 0.7784\n",
            "Epoch 8/15\n",
            " - 1s - loss: 0.3223 - acc: 0.8699 - val_loss: 0.4929 - val_acc: 0.7742\n",
            "Epoch 9/15\n",
            " - 1s - loss: 0.3058 - acc: 0.8823 - val_loss: 0.4971 - val_acc: 0.7684\n",
            "Epoch 10/15\n",
            " - 1s - loss: 0.2884 - acc: 0.8875 - val_loss: 0.4918 - val_acc: 0.7705\n",
            "Epoch 11/15\n",
            " - 1s - loss: 0.2734 - acc: 0.8979 - val_loss: 0.4945 - val_acc: 0.7700\n",
            "Epoch 12/15\n",
            " - 1s - loss: 0.2591 - acc: 0.9072 - val_loss: 0.5017 - val_acc: 0.7668\n",
            "Epoch 13/15\n",
            " - 1s - loss: 0.2471 - acc: 0.9084 - val_loss: 0.4940 - val_acc: 0.7710\n",
            "Epoch 14/15\n",
            " - 1s - loss: 0.2303 - acc: 0.9221 - val_loss: 0.4963 - val_acc: 0.7752\n",
            "Epoch 15/15\n",
            " - 1s - loss: 0.2198 - acc: 0.9285 - val_loss: 0.5138 - val_acc: 0.7621\n",
            "<keras.callbacks.History object at 0x7fc78cf1b080>\n",
            "1 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 4s - loss: 0.8390 - acc: 0.5632 - val_loss: 0.6128 - val_acc: 0.6921\n",
            "Epoch 2/15\n",
            " - 1s - loss: 0.5658 - acc: 0.7256 - val_loss: 0.6001 - val_acc: 0.6905\n",
            "Epoch 3/15\n",
            " - 1s - loss: 0.4880 - acc: 0.7727 - val_loss: 0.5272 - val_acc: 0.7436\n",
            "Epoch 4/15\n",
            " - 1s - loss: 0.4275 - acc: 0.8046 - val_loss: 0.5231 - val_acc: 0.7546\n",
            "Epoch 5/15\n",
            " - 1s - loss: 0.3942 - acc: 0.8268 - val_loss: 0.5092 - val_acc: 0.7588\n",
            "Epoch 6/15\n",
            " - 1s - loss: 0.3707 - acc: 0.8429 - val_loss: 0.5023 - val_acc: 0.7614\n",
            "Epoch 7/15\n",
            " - 1s - loss: 0.3430 - acc: 0.8613 - val_loss: 0.4996 - val_acc: 0.7677\n",
            "Epoch 8/15\n",
            " - 1s - loss: 0.3278 - acc: 0.8681 - val_loss: 0.4996 - val_acc: 0.7614\n",
            "Epoch 9/15\n",
            " - 1s - loss: 0.3127 - acc: 0.8732 - val_loss: 0.4999 - val_acc: 0.7646\n",
            "Epoch 10/15\n",
            " - 1s - loss: 0.2931 - acc: 0.8841 - val_loss: 0.4964 - val_acc: 0.7620\n",
            "Epoch 11/15\n",
            " - 1s - loss: 0.2747 - acc: 0.8989 - val_loss: 0.4957 - val_acc: 0.7651\n",
            "Epoch 12/15\n",
            " - 1s - loss: 0.2642 - acc: 0.9019 - val_loss: 0.4997 - val_acc: 0.7688\n",
            "Epoch 13/15\n",
            " - 1s - loss: 0.2517 - acc: 0.9060 - val_loss: 0.4996 - val_acc: 0.7704\n",
            "Epoch 14/15\n",
            " - 1s - loss: 0.2335 - acc: 0.9184 - val_loss: 0.5020 - val_acc: 0.7677\n",
            "Epoch 15/15\n",
            " - 1s - loss: 0.2292 - acc: 0.9208 - val_loss: 0.5048 - val_acc: 0.7704\n",
            "<keras.callbacks.History object at 0x7fc78cced828>\n",
            "2 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 3s - loss: 0.7246 - acc: 0.5930 - val_loss: 0.6044 - val_acc: 0.7026\n",
            "Epoch 2/15\n",
            " - 1s - loss: 0.5108 - acc: 0.7553 - val_loss: 0.5666 - val_acc: 0.7194\n",
            "Epoch 3/15\n",
            " - 1s - loss: 0.4451 - acc: 0.7982 - val_loss: 0.5531 - val_acc: 0.7346\n",
            "Epoch 4/15\n",
            " - 1s - loss: 0.4086 - acc: 0.8201 - val_loss: 0.5402 - val_acc: 0.7530\n",
            "Epoch 5/15\n",
            " - 1s - loss: 0.3660 - acc: 0.8441 - val_loss: 0.5344 - val_acc: 0.7551\n",
            "Epoch 6/15\n",
            " - 1s - loss: 0.3411 - acc: 0.8562 - val_loss: 0.5301 - val_acc: 0.7620\n",
            "Epoch 7/15\n",
            " - 1s - loss: 0.3197 - acc: 0.8720 - val_loss: 0.5297 - val_acc: 0.7667\n",
            "Epoch 8/15\n",
            " - 1s - loss: 0.3008 - acc: 0.8835 - val_loss: 0.5302 - val_acc: 0.7625\n",
            "Epoch 9/15\n",
            " - 1s - loss: 0.2816 - acc: 0.8961 - val_loss: 0.5348 - val_acc: 0.7656\n",
            "Epoch 10/15\n",
            " - 1s - loss: 0.2691 - acc: 0.9007 - val_loss: 0.5345 - val_acc: 0.7599\n",
            "Epoch 11/15\n",
            " - 1s - loss: 0.2526 - acc: 0.9095 - val_loss: 0.5351 - val_acc: 0.7641\n",
            "Epoch 12/15\n",
            " - 1s - loss: 0.2402 - acc: 0.9151 - val_loss: 0.5400 - val_acc: 0.7593\n",
            "Epoch 13/15\n",
            " - 1s - loss: 0.2255 - acc: 0.9207 - val_loss: 0.5380 - val_acc: 0.7572\n",
            "Epoch 14/15\n",
            " - 1s - loss: 0.2109 - acc: 0.9342 - val_loss: 0.5421 - val_acc: 0.7541\n",
            "Epoch 15/15\n",
            " - 1s - loss: 0.1979 - acc: 0.9399 - val_loss: 0.5448 - val_acc: 0.7599\n",
            "<keras.callbacks.History object at 0x7fc78ca451d0>\n",
            "3 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 3s - loss: 0.7873 - acc: 0.5800 - val_loss: 0.5805 - val_acc: 0.7120\n",
            "Epoch 2/15\n",
            " - 1s - loss: 0.5555 - acc: 0.7292 - val_loss: 0.5049 - val_acc: 0.7635\n",
            "Epoch 3/15\n",
            " - 1s - loss: 0.4847 - acc: 0.7744 - val_loss: 0.4807 - val_acc: 0.7856\n",
            "Epoch 4/15\n",
            " - 1s - loss: 0.4354 - acc: 0.8040 - val_loss: 0.4694 - val_acc: 0.7945\n",
            "Epoch 5/15\n",
            " - 1s - loss: 0.4053 - acc: 0.8266 - val_loss: 0.4630 - val_acc: 0.8008\n",
            "Epoch 6/15\n",
            " - 1s - loss: 0.3774 - acc: 0.8420 - val_loss: 0.4615 - val_acc: 0.8024\n",
            "Epoch 7/15\n",
            " - 1s - loss: 0.3526 - acc: 0.8539 - val_loss: 0.4552 - val_acc: 0.7987\n",
            "Epoch 8/15\n",
            " - 1s - loss: 0.3323 - acc: 0.8657 - val_loss: 0.4527 - val_acc: 0.8014\n",
            "Epoch 9/15\n",
            " - 1s - loss: 0.3185 - acc: 0.8767 - val_loss: 0.4491 - val_acc: 0.8008\n",
            "Epoch 10/15\n",
            " - 1s - loss: 0.2994 - acc: 0.8842 - val_loss: 0.4474 - val_acc: 0.8035\n",
            "Epoch 11/15\n",
            " - 1s - loss: 0.2855 - acc: 0.8946 - val_loss: 0.4487 - val_acc: 0.8014\n",
            "Epoch 12/15\n",
            " - 1s - loss: 0.2653 - acc: 0.9079 - val_loss: 0.4490 - val_acc: 0.7987\n",
            "Epoch 13/15\n",
            " - 1s - loss: 0.2558 - acc: 0.9081 - val_loss: 0.4490 - val_acc: 0.8014\n",
            "Epoch 14/15\n",
            " - 1s - loss: 0.2491 - acc: 0.9130 - val_loss: 0.4473 - val_acc: 0.8008\n",
            "Epoch 15/15\n",
            " - 1s - loss: 0.2291 - acc: 0.9205 - val_loss: 0.4497 - val_acc: 0.7998\n",
            "<keras.callbacks.History object at 0x7fc78c8157b8>\n",
            "4 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gwbxSBoM1hZ",
        "colab_type": "code",
        "outputId": "8fab4cba-2c0b-4f9b-df13-ac61ef596ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7324403789611239"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhKODlWKM7mo",
        "colab_type": "code",
        "outputId": "c552927d-b4e8-42bb-979b-22917ba85d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    conc = concatenate([avg_pool, max_pool])\n",
        "    conc = Dense(64, activation=\"relu\")(conc)\n",
        "    conc = Dropout(0.1)(conc)\n",
        "    outp = Dense(1, activation=\"sigmoid\")(conc)\n",
        "    model = Model(inputs=inp, outputs=outp)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix, nb_words, embedding_size)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 4s - loss: 0.6294 - acc: 0.6534 - val_loss: 0.5754 - val_acc: 0.7264\n",
            "Epoch 2/15\n",
            " - 2s - loss: 0.4953 - acc: 0.7753 - val_loss: 0.4601 - val_acc: 0.7878\n",
            "Epoch 3/15\n",
            " - 2s - loss: 0.4344 - acc: 0.8106 - val_loss: 0.4548 - val_acc: 0.7899\n",
            "Epoch 4/15\n",
            " - 2s - loss: 0.3977 - acc: 0.8271 - val_loss: 0.4514 - val_acc: 0.7946\n",
            "Epoch 5/15\n",
            " - 2s - loss: 0.3782 - acc: 0.8418 - val_loss: 0.4451 - val_acc: 0.7967\n",
            "Epoch 6/15\n",
            " - 2s - loss: 0.3645 - acc: 0.8481 - val_loss: 0.4432 - val_acc: 0.7988\n",
            "Epoch 7/15\n",
            " - 2s - loss: 0.3640 - acc: 0.8445 - val_loss: 0.4601 - val_acc: 0.7904\n",
            "Epoch 8/15\n",
            " - 2s - loss: 0.3445 - acc: 0.8576 - val_loss: 0.5145 - val_acc: 0.7831\n",
            "Epoch 9/15\n",
            " - 2s - loss: 0.3436 - acc: 0.8564 - val_loss: 0.4649 - val_acc: 0.7925\n",
            "Epoch 10/15\n",
            " - 2s - loss: 0.3237 - acc: 0.8671 - val_loss: 0.4582 - val_acc: 0.7889\n",
            "Epoch 11/15\n",
            " - 2s - loss: 0.3070 - acc: 0.8758 - val_loss: 0.5133 - val_acc: 0.7899\n",
            "Epoch 12/15\n",
            " - 2s - loss: 0.2926 - acc: 0.8835 - val_loss: 0.4763 - val_acc: 0.7868\n",
            "Epoch 13/15\n",
            " - 2s - loss: 0.2775 - acc: 0.8935 - val_loss: 0.5308 - val_acc: 0.7878\n",
            "Epoch 14/15\n",
            " - 2s - loss: 0.2714 - acc: 0.8932 - val_loss: 0.4843 - val_acc: 0.7883\n",
            "Epoch 15/15\n",
            " - 2s - loss: 0.2538 - acc: 0.9021 - val_loss: 0.5099 - val_acc: 0.7852\n",
            "<keras.callbacks.History object at 0x7fc78c68f128>\n",
            "1 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6283 - acc: 0.6665 - val_loss: 0.5556 - val_acc: 0.7310\n",
            "Epoch 2/15\n",
            " - 2s - loss: 0.4936 - acc: 0.7774 - val_loss: 0.4775 - val_acc: 0.7919\n",
            "Epoch 3/15\n",
            " - 2s - loss: 0.4240 - acc: 0.8138 - val_loss: 0.4694 - val_acc: 0.7940\n",
            "Epoch 4/15\n",
            " - 2s - loss: 0.3956 - acc: 0.8303 - val_loss: 0.4476 - val_acc: 0.8050\n",
            "Epoch 5/15\n",
            " - 2s - loss: 0.3788 - acc: 0.8371 - val_loss: 0.5047 - val_acc: 0.7719\n",
            "Epoch 6/15\n",
            " - 2s - loss: 0.3791 - acc: 0.8387 - val_loss: 0.4532 - val_acc: 0.7951\n",
            "Epoch 7/15\n",
            " - 2s - loss: 0.3505 - acc: 0.8545 - val_loss: 0.4640 - val_acc: 0.7903\n",
            "Epoch 8/15\n",
            " - 2s - loss: 0.3322 - acc: 0.8580 - val_loss: 0.4646 - val_acc: 0.7930\n",
            "Epoch 9/15\n",
            " - 2s - loss: 0.3174 - acc: 0.8687 - val_loss: 0.4771 - val_acc: 0.7919\n",
            "Epoch 10/15\n",
            " - 2s - loss: 0.3083 - acc: 0.8737 - val_loss: 0.4839 - val_acc: 0.7888\n",
            "Epoch 11/15\n",
            " - 2s - loss: 0.2941 - acc: 0.8800 - val_loss: 0.4910 - val_acc: 0.7893\n",
            "Epoch 12/15\n",
            " - 2s - loss: 0.2730 - acc: 0.8879 - val_loss: 0.5120 - val_acc: 0.7846\n",
            "Epoch 13/15\n",
            " - 2s - loss: 0.2494 - acc: 0.9004 - val_loss: 0.5232 - val_acc: 0.7893\n",
            "Epoch 14/15\n",
            " - 2s - loss: 0.2281 - acc: 0.9133 - val_loss: 0.5620 - val_acc: 0.7788\n",
            "Epoch 15/15\n",
            " - 2s - loss: 0.2102 - acc: 0.9212 - val_loss: 0.5845 - val_acc: 0.7803\n",
            "<keras.callbacks.History object at 0x7fc78c31a828>\n",
            "2 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6419 - acc: 0.6539 - val_loss: 0.5751 - val_acc: 0.7199\n",
            "Epoch 2/15\n",
            " - 2s - loss: 0.5167 - acc: 0.7646 - val_loss: 0.5023 - val_acc: 0.7656\n",
            "Epoch 3/15\n",
            " - 2s - loss: 0.4363 - acc: 0.8089 - val_loss: 0.4775 - val_acc: 0.7914\n",
            "Epoch 4/15\n",
            " - 2s - loss: 0.4012 - acc: 0.8194 - val_loss: 0.4871 - val_acc: 0.7814\n",
            "Epoch 5/15\n",
            " - 2s - loss: 0.3854 - acc: 0.8342 - val_loss: 0.4712 - val_acc: 0.7851\n",
            "Epoch 6/15\n",
            " - 2s - loss: 0.3641 - acc: 0.8441 - val_loss: 0.4932 - val_acc: 0.7798\n",
            "Epoch 7/15\n",
            " - 2s - loss: 0.3484 - acc: 0.8522 - val_loss: 0.4796 - val_acc: 0.7803\n",
            "Epoch 8/15\n",
            " - 2s - loss: 0.3341 - acc: 0.8641 - val_loss: 0.5028 - val_acc: 0.7761\n",
            "Epoch 9/15\n",
            " - 2s - loss: 0.3178 - acc: 0.8657 - val_loss: 0.5073 - val_acc: 0.7677\n",
            "Epoch 10/15\n",
            " - 2s - loss: 0.3053 - acc: 0.8764 - val_loss: 0.5332 - val_acc: 0.7604\n",
            "Epoch 11/15\n",
            " - 2s - loss: 0.2855 - acc: 0.8863 - val_loss: 0.5585 - val_acc: 0.7388\n",
            "Epoch 12/15\n",
            " - 2s - loss: 0.2674 - acc: 0.8947 - val_loss: 0.5677 - val_acc: 0.7562\n",
            "Epoch 13/15\n",
            " - 2s - loss: 0.2621 - acc: 0.8939 - val_loss: 0.5533 - val_acc: 0.7457\n",
            "Epoch 14/15\n",
            " - 2s - loss: 0.2407 - acc: 0.9123 - val_loss: 0.5879 - val_acc: 0.7509\n",
            "Epoch 15/15\n",
            " - 2s - loss: 0.2223 - acc: 0.9144 - val_loss: 0.5814 - val_acc: 0.7541\n",
            "<keras.callbacks.History object at 0x7fc78bde87b8>\n",
            "3 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 5s - loss: 0.6454 - acc: 0.6434 - val_loss: 0.5568 - val_acc: 0.7478\n",
            "Epoch 2/15\n",
            " - 2s - loss: 0.5235 - acc: 0.7664 - val_loss: 0.4635 - val_acc: 0.7824\n",
            "Epoch 3/15\n",
            " - 2s - loss: 0.4495 - acc: 0.8042 - val_loss: 0.4281 - val_acc: 0.8114\n",
            "Epoch 4/15\n",
            " - 2s - loss: 0.4165 - acc: 0.8189 - val_loss: 0.4364 - val_acc: 0.7987\n",
            "Epoch 5/15\n",
            " - 2s - loss: 0.3979 - acc: 0.8303 - val_loss: 0.4107 - val_acc: 0.8061\n",
            "Epoch 6/15\n",
            " - 2s - loss: 0.3780 - acc: 0.8441 - val_loss: 0.4125 - val_acc: 0.8177\n",
            "Epoch 7/15\n",
            " - 2s - loss: 0.3678 - acc: 0.8457 - val_loss: 0.4476 - val_acc: 0.8008\n",
            "Epoch 8/15\n",
            " - 2s - loss: 0.3690 - acc: 0.8469 - val_loss: 0.4092 - val_acc: 0.8171\n",
            "Epoch 9/15\n",
            " - 2s - loss: 0.3455 - acc: 0.8583 - val_loss: 0.4148 - val_acc: 0.8129\n",
            "Epoch 10/15\n",
            " - 2s - loss: 0.3226 - acc: 0.8702 - val_loss: 0.4177 - val_acc: 0.8213\n",
            "Epoch 11/15\n",
            " - 2s - loss: 0.3106 - acc: 0.8744 - val_loss: 0.4368 - val_acc: 0.8224\n",
            "Epoch 12/15\n",
            " - 2s - loss: 0.2956 - acc: 0.8837 - val_loss: 0.4265 - val_acc: 0.8014\n",
            "Epoch 13/15\n",
            " - 2s - loss: 0.2797 - acc: 0.8911 - val_loss: 0.4474 - val_acc: 0.8056\n",
            "Epoch 14/15\n",
            " - 2s - loss: 0.2754 - acc: 0.8893 - val_loss: 0.4638 - val_acc: 0.8145\n",
            "Epoch 15/15\n",
            " - 2s - loss: 0.2543 - acc: 0.9035 - val_loss: 0.4523 - val_acc: 0.8098\n",
            "<keras.callbacks.History object at 0x7fc78bc5b9e8>\n",
            "4 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87ncjeymNNeF",
        "colab_type": "code",
        "outputId": "2af0dad5-2039-4cd2-f627-063ac02b65b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7389804522805673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wKUDjhNNRmk",
        "colab_type": "code",
        "outputId": "3fa8a3b0-37e3-40e7-d436-368198548e35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(48, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "embedding_matrix_para, nb_words = load_para(word_dict, lemma_dict)\n",
        "# embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_para), axis=1)\n",
        "embedding_matrix = np.concatenate((0.60*embedding_matrix_glove, 0.40*embedding_matrix_fasttext), axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix, nb_words, embedding_size)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  4%|▎         | 1271/34498 [00:00<00:02, 12698.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34498/34498 [00:06<00:00, 5738.03it/s]\n",
            "  4%|▍         | 1318/34498 [00:00<00:02, 13112.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[-1. -1. -1. -1. -1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 34498/34498 [00:05<00:00, 6138.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 25s - loss: 0.6476 - acc: 0.6085 - val_loss: 0.5740 - val_acc: 0.7405\n",
            "Epoch 2/15\n",
            " - 13s - loss: 0.5045 - acc: 0.7700 - val_loss: 0.4661 - val_acc: 0.7931\n",
            "Epoch 3/15\n",
            " - 13s - loss: 0.4295 - acc: 0.8143 - val_loss: 0.4710 - val_acc: 0.7899\n",
            "Epoch 4/15\n",
            " - 13s - loss: 0.3958 - acc: 0.8285 - val_loss: 0.4510 - val_acc: 0.7915\n",
            "Epoch 5/15\n",
            " - 13s - loss: 0.3775 - acc: 0.8425 - val_loss: 0.4482 - val_acc: 0.7920\n",
            "Epoch 6/15\n",
            " - 13s - loss: 0.3621 - acc: 0.8471 - val_loss: 0.4568 - val_acc: 0.7931\n",
            "Epoch 7/15\n",
            " - 13s - loss: 0.3476 - acc: 0.8550 - val_loss: 0.4846 - val_acc: 0.7868\n",
            "Epoch 8/15\n",
            " - 13s - loss: 0.3443 - acc: 0.8609 - val_loss: 0.4856 - val_acc: 0.7889\n",
            "Epoch 9/15\n",
            " - 13s - loss: 0.3230 - acc: 0.8653 - val_loss: 0.4674 - val_acc: 0.7957\n",
            "Epoch 10/15\n",
            " - 13s - loss: 0.3072 - acc: 0.8800 - val_loss: 0.5021 - val_acc: 0.7889\n",
            "Epoch 11/15\n",
            " - 13s - loss: 0.2895 - acc: 0.8847 - val_loss: 0.5177 - val_acc: 0.7868\n",
            "Epoch 12/15\n",
            " - 12s - loss: 0.2771 - acc: 0.8923 - val_loss: 0.5363 - val_acc: 0.7789\n",
            "Epoch 13/15\n",
            " - 13s - loss: 0.2790 - acc: 0.8921 - val_loss: 0.5727 - val_acc: 0.7894\n",
            "Epoch 14/15\n",
            " - 13s - loss: 0.2501 - acc: 0.9073 - val_loss: 0.5795 - val_acc: 0.7883\n",
            "Epoch 15/15\n",
            " - 13s - loss: 0.2341 - acc: 0.9094 - val_loss: 0.6081 - val_acc: 0.7878\n",
            "<keras.callbacks.History object at 0x7f1560ed4cc0>\n",
            "1 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 25s - loss: 0.6314 - acc: 0.6630 - val_loss: 0.5799 - val_acc: 0.6784\n",
            "Epoch 2/15\n",
            " - 13s - loss: 0.4931 - acc: 0.7765 - val_loss: 0.4749 - val_acc: 0.7861\n",
            "Epoch 3/15\n",
            " - 13s - loss: 0.4335 - acc: 0.8075 - val_loss: 0.4466 - val_acc: 0.8071\n",
            "Epoch 4/15\n",
            " - 13s - loss: 0.4017 - acc: 0.8319 - val_loss: 0.4609 - val_acc: 0.8014\n",
            "Epoch 5/15\n",
            " - 13s - loss: 0.3872 - acc: 0.8338 - val_loss: 0.4516 - val_acc: 0.7977\n",
            "Epoch 6/15\n",
            " - 13s - loss: 0.3728 - acc: 0.8448 - val_loss: 0.4567 - val_acc: 0.7966\n",
            "Epoch 7/15\n",
            " - 13s - loss: 0.3623 - acc: 0.8473 - val_loss: 0.4630 - val_acc: 0.7930\n",
            "Epoch 8/15\n",
            " - 13s - loss: 0.3446 - acc: 0.8550 - val_loss: 0.4675 - val_acc: 0.7935\n",
            "Epoch 9/15\n",
            " - 13s - loss: 0.3282 - acc: 0.8658 - val_loss: 0.5086 - val_acc: 0.7882\n",
            "Epoch 10/15\n",
            " - 13s - loss: 0.3174 - acc: 0.8718 - val_loss: 0.4848 - val_acc: 0.7966\n",
            "Epoch 11/15\n",
            " - 13s - loss: 0.2939 - acc: 0.8825 - val_loss: 0.5258 - val_acc: 0.7846\n",
            "Epoch 12/15\n",
            " - 13s - loss: 0.2838 - acc: 0.8863 - val_loss: 0.5774 - val_acc: 0.7599\n",
            "Epoch 13/15\n",
            " - 13s - loss: 0.2640 - acc: 0.8958 - val_loss: 0.5747 - val_acc: 0.7730\n",
            "Epoch 14/15\n",
            " - 13s - loss: 0.2413 - acc: 0.9061 - val_loss: 0.6615 - val_acc: 0.7578\n",
            "Epoch 15/15\n",
            " - 13s - loss: 0.2373 - acc: 0.9061 - val_loss: 0.7028 - val_acc: 0.7525\n",
            "<keras.callbacks.History object at 0x7f155f813588>\n",
            "2 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 26s - loss: 0.6456 - acc: 0.6231 - val_loss: 0.5526 - val_acc: 0.7415\n",
            "Epoch 2/15\n",
            " - 13s - loss: 0.4796 - acc: 0.7844 - val_loss: 0.4880 - val_acc: 0.7709\n",
            "Epoch 3/15\n",
            " - 12s - loss: 0.4241 - acc: 0.8140 - val_loss: 0.4821 - val_acc: 0.7793\n",
            "Epoch 4/15\n",
            " - 13s - loss: 0.3929 - acc: 0.8238 - val_loss: 0.4802 - val_acc: 0.7793\n",
            "Epoch 5/15\n",
            " - 13s - loss: 0.3727 - acc: 0.8389 - val_loss: 0.4980 - val_acc: 0.7903\n",
            "Epoch 6/15\n",
            " - 13s - loss: 0.3600 - acc: 0.8469 - val_loss: 0.5176 - val_acc: 0.7641\n",
            "Epoch 7/15\n",
            " - 12s - loss: 0.3457 - acc: 0.8538 - val_loss: 0.5343 - val_acc: 0.7635\n",
            "Epoch 8/15\n",
            " - 13s - loss: 0.3350 - acc: 0.8585 - val_loss: 0.5249 - val_acc: 0.7719\n",
            "Epoch 9/15\n",
            " - 12s - loss: 0.3161 - acc: 0.8664 - val_loss: 0.5860 - val_acc: 0.7520\n",
            "Epoch 10/15\n",
            " - 13s - loss: 0.3131 - acc: 0.8676 - val_loss: 0.5652 - val_acc: 0.7604\n",
            "Epoch 11/15\n",
            " - 13s - loss: 0.2925 - acc: 0.8820 - val_loss: 0.5867 - val_acc: 0.7535\n",
            "Epoch 12/15\n",
            " - 13s - loss: 0.2669 - acc: 0.8925 - val_loss: 0.6230 - val_acc: 0.7388\n",
            "Epoch 13/15\n",
            " - 13s - loss: 0.2486 - acc: 0.8968 - val_loss: 0.7105 - val_acc: 0.7425\n",
            "Epoch 14/15\n",
            " - 12s - loss: 0.2571 - acc: 0.8951 - val_loss: 0.6577 - val_acc: 0.7446\n",
            "Epoch 15/15\n",
            " - 13s - loss: 0.2270 - acc: 0.9070 - val_loss: 0.7242 - val_acc: 0.7373\n",
            "<keras.callbacks.History object at 0x7f149ffd5518>\n",
            "3 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 26s - loss: 0.6450 - acc: 0.6079 - val_loss: 0.5371 - val_acc: 0.7462\n",
            "Epoch 2/15\n",
            " - 12s - loss: 0.4940 - acc: 0.7779 - val_loss: 0.4512 - val_acc: 0.8040\n",
            "Epoch 3/15\n",
            " - 13s - loss: 0.4352 - acc: 0.8072 - val_loss: 0.4221 - val_acc: 0.8135\n",
            "Epoch 4/15\n",
            " - 13s - loss: 0.4075 - acc: 0.8256 - val_loss: 0.4064 - val_acc: 0.8140\n",
            "Epoch 5/15\n",
            " - 12s - loss: 0.3921 - acc: 0.8333 - val_loss: 0.4041 - val_acc: 0.8145\n",
            "Epoch 6/15\n",
            " - 13s - loss: 0.3701 - acc: 0.8462 - val_loss: 0.4149 - val_acc: 0.8103\n",
            "Epoch 7/15\n",
            " - 13s - loss: 0.3577 - acc: 0.8524 - val_loss: 0.4259 - val_acc: 0.8166\n",
            "Epoch 8/15\n",
            " - 13s - loss: 0.3416 - acc: 0.8573 - val_loss: 0.4472 - val_acc: 0.8098\n",
            "Epoch 9/15\n",
            " - 13s - loss: 0.3452 - acc: 0.8522 - val_loss: 0.4308 - val_acc: 0.8129\n",
            "Epoch 10/15\n",
            " - 12s - loss: 0.3197 - acc: 0.8688 - val_loss: 0.4376 - val_acc: 0.8087\n",
            "Epoch 11/15\n",
            " - 13s - loss: 0.2955 - acc: 0.8827 - val_loss: 0.5080 - val_acc: 0.7798\n",
            "Epoch 12/15\n",
            " - 13s - loss: 0.2973 - acc: 0.8744 - val_loss: 0.4394 - val_acc: 0.8119\n",
            "Epoch 13/15\n",
            " - 13s - loss: 0.2676 - acc: 0.8968 - val_loss: 0.4809 - val_acc: 0.7977\n",
            "Epoch 14/15\n",
            " - 13s - loss: 0.2445 - acc: 0.9014 - val_loss: 0.6984 - val_acc: 0.7546\n",
            "Epoch 15/15\n",
            " - 12s - loss: 0.2510 - acc: 0.9009 - val_loss: 0.5501 - val_acc: 0.7867\n",
            "<keras.callbacks.History object at 0x7f149f22cc50>\n",
            "4 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxN8CYMLemSD",
        "colab_type": "code",
        "outputId": "4bd17a1c-cade-4d44-b323-42bfd026dc41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7389804522805673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd0DncfOeoGH",
        "colab_type": "code",
        "outputId": "d9986f8f-52fd-43ad-ee81-5256955504c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=600):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(48, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        "    return model\n",
        "# embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "# embedding_matrix_para, nb_words = load_para(word_dict, lemma_dict)\n",
        "# embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_para), axis=1)\n",
        "embedding_matrix = np.concatenate((0.20*embedding_matrix_glove, 0.80*embedding_matrix_fasttext), axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix, nb_words, embedding_size)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 28s - loss: 0.6540 - acc: 0.6045 - val_loss: 0.6180 - val_acc: 0.7190\n",
            "Epoch 2/15\n",
            " - 13s - loss: 0.5224 - acc: 0.7683 - val_loss: 0.4909 - val_acc: 0.7621\n",
            "Epoch 3/15\n",
            " - 13s - loss: 0.4490 - acc: 0.8014 - val_loss: 0.4744 - val_acc: 0.7747\n",
            "Epoch 4/15\n",
            " - 13s - loss: 0.4069 - acc: 0.8252 - val_loss: 0.4827 - val_acc: 0.7784\n",
            "Epoch 5/15\n",
            " - 13s - loss: 0.4061 - acc: 0.8280 - val_loss: 0.4709 - val_acc: 0.7836\n",
            "Epoch 6/15\n",
            " - 13s - loss: 0.3820 - acc: 0.8332 - val_loss: 0.4546 - val_acc: 0.7978\n",
            "Epoch 7/15\n",
            " - 13s - loss: 0.3602 - acc: 0.8506 - val_loss: 0.4657 - val_acc: 0.7952\n",
            "Epoch 8/15\n",
            " - 13s - loss: 0.3509 - acc: 0.8504 - val_loss: 0.4826 - val_acc: 0.7805\n",
            "Epoch 9/15\n",
            " - 13s - loss: 0.3270 - acc: 0.8628 - val_loss: 0.4792 - val_acc: 0.7973\n",
            "Epoch 10/15\n",
            " - 13s - loss: 0.3082 - acc: 0.8751 - val_loss: 0.4975 - val_acc: 0.7889\n",
            "Epoch 11/15\n",
            " - 13s - loss: 0.2869 - acc: 0.8840 - val_loss: 0.5437 - val_acc: 0.7873\n",
            "Epoch 12/15\n",
            " - 13s - loss: 0.2711 - acc: 0.8954 - val_loss: 0.5247 - val_acc: 0.7742\n",
            "Epoch 13/15\n",
            " - 13s - loss: 0.2505 - acc: 0.9002 - val_loss: 0.5721 - val_acc: 0.7736\n",
            "Epoch 14/15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtQ6Fmzaf4eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do_IidMgKlGu",
        "colab_type": "code",
        "outputId": "9e534c03-0d01-458d-9e54-e9750c60cba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix_para.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34504, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOURqzSZKN6b",
        "colab_type": "code",
        "outputId": "42fdc10c-b0a7-4db7-e5e2-d4857a265135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(48, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "# embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "# embedding_matrix_para, nb_words = load_para(word_dict, lemma_dict)\n",
        "# embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_para), axis=1)\n",
        "# embedding_matrix = np.concatenate((0.60*embedding_matrix_glove, 0.40*embedding_matrix_fasttext), axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix_glove, nb_words, embedding_size=300)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "# print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5709 samples, validate on 1904 samples\n",
            "Epoch 1/15\n",
            " - 7s - loss: 0.6169 - acc: 0.6637 - val_loss: 0.5010 - val_acc: 0.7700\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4579 - acc: 0.7996 - val_loss: 0.4568 - val_acc: 0.7946\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4062 - acc: 0.8224 - val_loss: 0.4432 - val_acc: 0.8025\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.3863 - acc: 0.8352 - val_loss: 0.4512 - val_acc: 0.8015\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3677 - acc: 0.8439 - val_loss: 0.4606 - val_acc: 0.7988\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3551 - acc: 0.8511 - val_loss: 0.4511 - val_acc: 0.7978\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3350 - acc: 0.8592 - val_loss: 0.4541 - val_acc: 0.7910\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3212 - acc: 0.8681 - val_loss: 0.4920 - val_acc: 0.7941\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.3015 - acc: 0.8734 - val_loss: 0.5312 - val_acc: 0.7878\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.3116 - acc: 0.8697 - val_loss: 0.4748 - val_acc: 0.7920\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.2745 - acc: 0.8912 - val_loss: 0.5148 - val_acc: 0.7826\n",
            "Epoch 12/15\n",
            " - 3s - loss: 0.2556 - acc: 0.8995 - val_loss: 0.5412 - val_acc: 0.7841\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.2493 - acc: 0.9040 - val_loss: 0.5528 - val_acc: 0.7810\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.2175 - acc: 0.9163 - val_loss: 0.5903 - val_acc: 0.7752\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.2044 - acc: 0.9191 - val_loss: 0.6222 - val_acc: 0.7773\n",
            "<keras.callbacks.History object at 0x7fc78b834828>\n",
            "1 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 8s - loss: 0.6230 - acc: 0.6499 - val_loss: 0.4966 - val_acc: 0.7704\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4571 - acc: 0.7951 - val_loss: 0.4466 - val_acc: 0.8066\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4092 - acc: 0.8208 - val_loss: 0.4596 - val_acc: 0.8056\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.3946 - acc: 0.8275 - val_loss: 0.4513 - val_acc: 0.8003\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3743 - acc: 0.8377 - val_loss: 0.4574 - val_acc: 0.7956\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3587 - acc: 0.8480 - val_loss: 0.4681 - val_acc: 0.7982\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3487 - acc: 0.8538 - val_loss: 0.4922 - val_acc: 0.7898\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3339 - acc: 0.8587 - val_loss: 0.4713 - val_acc: 0.7867\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.3173 - acc: 0.8641 - val_loss: 0.5205 - val_acc: 0.7877\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.2951 - acc: 0.8765 - val_loss: 0.5154 - val_acc: 0.7909\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.2764 - acc: 0.8856 - val_loss: 0.5788 - val_acc: 0.7588\n",
            "Epoch 12/15\n",
            " - 3s - loss: 0.2696 - acc: 0.8900 - val_loss: 0.6197 - val_acc: 0.7667\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.2414 - acc: 0.8986 - val_loss: 0.6223 - val_acc: 0.7630\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.2262 - acc: 0.9086 - val_loss: 0.6707 - val_acc: 0.7604\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.2091 - acc: 0.9215 - val_loss: 0.7003 - val_acc: 0.7625\n",
            "<keras.callbacks.History object at 0x7fc78aefbef0>\n",
            "2 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 8s - loss: 0.6137 - acc: 0.6783 - val_loss: 0.5104 - val_acc: 0.7751\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4728 - acc: 0.7919 - val_loss: 0.4814 - val_acc: 0.7788\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4181 - acc: 0.8179 - val_loss: 0.4699 - val_acc: 0.7951\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.3938 - acc: 0.8254 - val_loss: 0.4695 - val_acc: 0.7856\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3735 - acc: 0.8364 - val_loss: 0.4811 - val_acc: 0.7788\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3674 - acc: 0.8410 - val_loss: 0.4830 - val_acc: 0.7893\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3584 - acc: 0.8492 - val_loss: 0.5045 - val_acc: 0.7809\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3509 - acc: 0.8503 - val_loss: 0.5086 - val_acc: 0.7761\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.3307 - acc: 0.8601 - val_loss: 0.5320 - val_acc: 0.7730\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.3101 - acc: 0.8695 - val_loss: 0.5359 - val_acc: 0.7861\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.3010 - acc: 0.8706 - val_loss: 0.5383 - val_acc: 0.7672\n",
            "Epoch 12/15\n",
            " - 3s - loss: 0.2821 - acc: 0.8839 - val_loss: 0.5782 - val_acc: 0.7620\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.2533 - acc: 0.8970 - val_loss: 0.6315 - val_acc: 0.7578\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.2264 - acc: 0.9081 - val_loss: 0.6752 - val_acc: 0.7609\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.2157 - acc: 0.9147 - val_loss: 0.7233 - val_acc: 0.7310\n",
            "<keras.callbacks.History object at 0x7fc78acedda0>\n",
            "3 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n",
            "Train on 5710 samples, validate on 1903 samples\n",
            "Epoch 1/15\n",
            " - 8s - loss: 0.6392 - acc: 0.6221 - val_loss: 0.5245 - val_acc: 0.7588\n",
            "Epoch 2/15\n",
            " - 3s - loss: 0.4777 - acc: 0.7799 - val_loss: 0.4462 - val_acc: 0.8082\n",
            "Epoch 3/15\n",
            " - 3s - loss: 0.4242 - acc: 0.8161 - val_loss: 0.4232 - val_acc: 0.8145\n",
            "Epoch 4/15\n",
            " - 3s - loss: 0.3987 - acc: 0.8271 - val_loss: 0.4293 - val_acc: 0.8098\n",
            "Epoch 5/15\n",
            " - 3s - loss: 0.3975 - acc: 0.8271 - val_loss: 0.4217 - val_acc: 0.8071\n",
            "Epoch 6/15\n",
            " - 3s - loss: 0.3692 - acc: 0.8375 - val_loss: 0.4270 - val_acc: 0.7987\n",
            "Epoch 7/15\n",
            " - 3s - loss: 0.3553 - acc: 0.8522 - val_loss: 0.4808 - val_acc: 0.7930\n",
            "Epoch 8/15\n",
            " - 3s - loss: 0.3535 - acc: 0.8501 - val_loss: 0.4392 - val_acc: 0.8098\n",
            "Epoch 9/15\n",
            " - 3s - loss: 0.3288 - acc: 0.8602 - val_loss: 0.4764 - val_acc: 0.8008\n",
            "Epoch 10/15\n",
            " - 3s - loss: 0.3157 - acc: 0.8715 - val_loss: 0.4914 - val_acc: 0.8008\n",
            "Epoch 11/15\n",
            " - 3s - loss: 0.2932 - acc: 0.8816 - val_loss: 0.5141 - val_acc: 0.7966\n",
            "Epoch 12/15\n",
            " - 3s - loss: 0.2796 - acc: 0.8839 - val_loss: 0.5228 - val_acc: 0.8040\n",
            "Epoch 13/15\n",
            " - 3s - loss: 0.2643 - acc: 0.8972 - val_loss: 0.6163 - val_acc: 0.7851\n",
            "Epoch 14/15\n",
            " - 3s - loss: 0.2473 - acc: 0.8995 - val_loss: 0.5772 - val_acc: 0.7814\n",
            "Epoch 15/15\n",
            " - 3s - loss: 0.2115 - acc: 0.9215 - val_loss: 0.5881 - val_acc: 0.7935\n",
            "<keras.callbacks.History object at 0x7fc78a337c88>\n",
            "4 Fold Completed:  --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- --X-- \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WiwgwV4KN4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbOISfCrf7Cg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_lstm_atten(embedding_matrix, nb_words, embedding_size=300):\n",
        "    inp = Input(shape=(max_length,))\n",
        "    x = Embedding(nb_words, embedding_size, weights=[embedding_matrix], trainable=False)(inp)\n",
        "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = Dense(48, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        "    return model\n",
        "# embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)\n",
        "# embedding_matrix_para, nb_words = load_para(word_dict, lemma_dict)\n",
        "# embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_para), axis=1)\n",
        "# embedding_matrix = np.concatenate((0.20*embedding_matrix_glove, 0.80*embedding_matrix_fasttext), axis=1)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=4)\n",
        "skf.get_n_splits(train_word_sequences, y)\n",
        "cvscores = []\n",
        "i=1\n",
        "for train_1, test_1 in skf.split(train_word_sequences, y):\n",
        "  model = model_lstm_atten(embedding_matrix_para, nb_words, embedding_size)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  print(model.fit(train_word_sequences[train_1], y[train_1], epochs=15, batch_size=512, verbose=2, validation_data=(train_word_sequences[test_1], y[test_1])))\n",
        "\t# evaluate the model\n",
        "  # scores = model.evaluate(test_word_sequences[test], y[test], verbose=2)\n",
        "  # print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  # cvscores.append(scores[1] * 100)\n",
        "  print(i, \"Fold Completed: \",   \"--X-- \"*25)\n",
        "  i=i+1\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxSofP6WgJnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_prob=model.predict(test_word_sequences, batch_size=batch_size, verbose=2)\n",
        "f1_score(original['target'], submission['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGn-ZHhsNz7q",
        "colab_type": "text"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFdcGzMSgL4n",
        "colab_type": "code",
        "outputId": "f72dd76b-2efe-4f39-d44c-85dba5caf453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert_repo'...\n",
            "remote: Enumerating objects: 340, done.\u001b[K\n",
            "remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n",
            "Receiving objects: 100% (340/340), 300.28 KiB | 566.00 KiB/s, done.\n",
            "Resolving deltas: 100% (185/185), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBzhPmQVV12s",
        "colab_type": "code",
        "outputId": "501b4256-bcd6-4475-cdda-51efd17d8152",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 17.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-6UAy43TnFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from bert.tokenization import FullTokenizer\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Initialize session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Params for bert model and tokenization\n",
        "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "max_seq_length = 160"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qpPj-qGVU9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Layer\n",
        "\n",
        "class BertLayer(Layer):\n",
        "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
        "        self.n_fine_tune_layers = n_fine_tune_layers\n",
        "        self.trainable = True\n",
        "        self.output_size = 768\n",
        "        super(BertLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.bert = hub.Module(\n",
        "            bert_path,\n",
        "            trainable=self.trainable,\n",
        "            name=\"{}_module\".format(self.name)\n",
        "        )\n",
        "        trainable_vars = self.bert.variables\n",
        "        \n",
        "        # Remove unused layers\n",
        "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
        "        \n",
        "        # Select how many layers to fine tune\n",
        "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
        "        \n",
        "        # Add to trainable weights\n",
        "        for var in trainable_vars:\n",
        "            self._trainable_weights.append(var)\n",
        "        \n",
        "        # Add non-trainable weights\n",
        "        for var in self.bert.variables:\n",
        "            if var not in self._trainable_weights:\n",
        "                self._non_trainable_weights.append(var)\n",
        "        \n",
        "        super(BertLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
        "        input_ids, input_mask, segment_ids = inputs\n",
        "        bert_inputs = dict(\n",
        "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
        "        )\n",
        "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
        "            \"pooled_output\"\n",
        "        ]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.output_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ruTwLgVVCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model\n",
        "def build_model(max_seq_length): \n",
        "    in_id = Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "    in_mask = Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "    in_segment = Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "    bert_inputs = [in_id, in_mask, in_segment]\n",
        "    \n",
        "    bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
        "    dense = Dense(256, activation='relu')(bert_output)\n",
        "    pred = Dense(1, activation='sigmoid')(dense)\n",
        "    \n",
        "    model = Model(inputs=bert_inputs, outputs=pred)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def initialize_vars(sess):\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "    K.set_session(sess)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiaLGux9VVHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PaddingInputExample(object):\n",
        "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
        "  When running eval/predict on the TPU, we need to pad the number of examples\n",
        "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
        "  size. The alternative is to drop the last batch, which is bad because it means\n",
        "  the entire output data won't be generated.\n",
        "  We use this class instead of `None` because treating `None` as padding\n",
        "  battches could cause silent errors.\n",
        "  \"\"\"\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "    Args:\n",
        "      guid: Unique id for the example.\n",
        "      text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "        Only must be specified for sequence pair tasks.\n",
        "      label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    bert_module =  hub.Module(bert_path)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    vocab_file, do_lower_case = sess.run(\n",
        "        [\n",
        "            tokenization_info[\"vocab_file\"],\n",
        "            tokenization_info[\"do_lower_case\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
        "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
        "\n",
        "    if isinstance(example, PaddingInputExample):\n",
        "        input_ids = [0] * max_seq_length\n",
        "        input_mask = [0] * max_seq_length\n",
        "        segment_ids = [0] * max_seq_length\n",
        "        label = 0\n",
        "        return input_ids, input_mask, segment_ids, label\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    if len(tokens_a) > max_seq_length - 2:\n",
        "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
        "\n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    segment_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    segment_ids.append(0)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < max_seq_length:\n",
        "        input_ids.append(0)\n",
        "        input_mask.append(0)\n",
        "        segment_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    return input_ids, input_mask, segment_ids, example.label\n",
        "\n",
        "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        labels.append(label)\n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "        np.array(labels).reshape(-1, 1),\n",
        "    )\n",
        "\n",
        "def convert_text_to_examples(texts, labels):\n",
        "    \"\"\"Create InputExamples\"\"\"\n",
        "    InputExamples = []\n",
        "    for text, label in zip(texts, labels):\n",
        "        InputExamples.append(\n",
        "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
        "        )\n",
        "    return InputExamples\n",
        "\n",
        "def convert_text_to_examples_test(texts):\n",
        "  InputExamples = []\n",
        "  for text in texts:\n",
        "    InputExamples.append(InputExample(guid=None, text_a=\" \".join(text), text_b=None))\n",
        "    \n",
        "  return InputExamples\n",
        "def convert_examples_to_features_test(tokenizer, examples, max_seq_length=160):\n",
        "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
        "\n",
        "    input_ids, input_masks, segment_ids = [], [], []\n",
        "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
        "        input_id, input_mask, segment_id, label = convert_single_example(\n",
        "            tokenizer, example, max_seq_length\n",
        "        )\n",
        "        input_ids.append(input_id)\n",
        "        input_masks.append(input_mask)\n",
        "        segment_ids.append(segment_id)\n",
        "        \n",
        "    return (\n",
        "        np.array(input_ids),\n",
        "        np.array(input_masks),\n",
        "        np.array(segment_ids),\n",
        "           )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_DTETzBVVQr",
        "colab_type": "code",
        "outputId": "8756afe6-08e0-4ef0-f59c-4b052ed325b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Instantiate tokenizer\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F07PfxzhVVVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text, test_text, train_label, test_label = train_test_split( train['text'], train['target'], test_size=0.20, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WhqR9FYVVPc",
        "colab_type": "code",
        "outputId": "d1fe1bce-10af-4a51-f80c-88fc7862bd30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "6ca30b5153ba445aba1f6c8e02572907",
            "33824e61536b4d66afca544b57522507",
            "eee3b631420e4bb78bd2c20c488679b5",
            "ba16d539843b40728deaa5961a3dba6b",
            "ea1ed6957d2c4c9fba0a9921f88217a7",
            "be9259930e6a490996d4a2f29632e42d",
            "b5cf333e656c413bb594e2015e46ad3c",
            "201df7b729624a1886b1df9656a14973",
            "e6fa56ca7c5d4fa79822668edd122b01",
            "4601229ff2344f35a708a326331792ad",
            "27a323119c7b48508828bc819fc97bdd",
            "8a95c10493dc45f38caca4f3a05458dd",
            "d92d006ea96b4b48adbecddd7a8822ae",
            "8f059268509c426c834e150779f2b892",
            "25d5032a7ee34602bcac18df2f2bff7f",
            "768ad106f30745c4bf64b08fd6cd1f67"
          ]
        }
      },
      "source": [
        "# Convert data to InputExample format\n",
        "train_examples = convert_text_to_examples(train_text, train_label)\n",
        "test_examples = convert_text_to_examples(test_text, test_label)\n",
        "\n",
        "# Convert to features\n",
        "(train_input_ids, train_input_masks, train_segment_ids, train_labels\n",
        " ) = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
        "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
        ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ca30b5153ba445aba1f6c8e02572907",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=6090, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6fa56ca7c5d4fa79822668edd122b01",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=1523, style=ProgressSty…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAwrBu1aZV-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_submission_examples=convert_text_to_examples_test(test_df['text'])\n",
        "(test_input_ids_submisson, test_input_masks_submisson, test_segment_ids_submisson\n",
        ") = convert_examples_to_features_test(tokenizer, test_submission_examples, max_seq_length=max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VS9kCMOVVM-",
        "colab_type": "code",
        "outputId": "e83f40ce-9d81-44b6-e599-9de9a509dbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "in_id = Input(shape=(max_seq_length,), name=\"input_ids\")\n",
        "in_mask = Input(shape=(max_seq_length,), name=\"input_masks\")\n",
        "in_segment = Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
        "bert_inputs = [in_id, in_mask, in_segment]\n",
        "bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
        "dense = Dense(256, activation='relu')(bert_output)\n",
        "pred = Dense(1, activation='sigmoid')(dense)\n",
        "    \n",
        "model = Model(inputs=bert_inputs, outputs=pred)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9f04b108c197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0min_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0min_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input_masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0min_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"segment_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbert_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0min_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_segment\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_fine_tune_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlFwYyLzVVK1",
        "colab_type": "code",
        "outputId": "9cfa89dd-43a0-4ebe-b97f-2c8a0d5b3a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "history=model.fit(\n",
        "    [train_input_ids, train_input_masks, train_segment_ids], \n",
        "    train_labels,\n",
        "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
        "    epochs=5,\n",
        "    batch_size=128 )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2f0476433127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history=model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_segment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_segment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZJrZFM6VVFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs34CjBoVVA1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSTh8NieVU7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}